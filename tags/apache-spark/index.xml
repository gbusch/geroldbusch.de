<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Apache Spark on</title><link>https://gbusch.github.io/tags/apache-spark/</link><description>Recent content in Apache Spark on</description><generator>Hugo</generator><language>en</language><lastBuildDate>Tue, 18 Oct 2022 20:11:00 +0200</lastBuildDate><atom:link href="https://gbusch.github.io/tags/apache-spark/index.xml" rel="self" type="application/rss+xml"/><item><title>Autoloader in Databricks Delta Live Tables</title><link>https://gbusch.github.io/blog/databricks-autoloader/</link><pubDate>Tue, 18 Oct 2022 20:11:00 +0200</pubDate><guid>https://gbusch.github.io/blog/databricks-autoloader/</guid><description>Recently, we had the following challenge:</description></item><item><title>Read parquet files from Azure Data Lake with Apache Spark</title><link>https://gbusch.github.io/blog/spark-read-from-azure-datalake/</link><pubDate>Sun, 02 Oct 2022 20:28:57 +0200</pubDate><guid>https://gbusch.github.io/blog/spark-read-from-azure-datalake/</guid><description>Azure Blob Storage - and especially the Datalake Gen 2 which is built on top and allows additional features like hierarchical namespace - is a great place to store data in all kinds of format: a data lake.</description></item><item><title>Defining Spark Schemas with Strings in DDL</title><link>https://gbusch.github.io/blog/spark-ddl-schema/</link><pubDate>Mon, 25 Jul 2022 20:28:57 +0200</pubDate><guid>https://gbusch.github.io/blog/spark-ddl-schema/</guid><description>Defining a schema in Spark can sometimes be tedious and confusing.</description></item></channel></rss>